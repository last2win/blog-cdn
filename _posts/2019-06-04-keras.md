---
layout: post
title: Python-keras和tensorflow使用 keras.callbacks.TensorBoard 可视化数据
categories: [机器学习]
description: "Python-keras和tensorflow使用 keras.callbacks.TensorBoard 可视化数据"
keywords: 机器学习, Python, keras, tensorflow, TensorBoard
---

此文首发于我的个人博客：[zhang0peter的个人博客](https://zhang0peter.com)         

{% raw %}
***          
{% endraw %}


TensorBoard 是一个非常好用的可视化工具
### 1.数据写入
在keras中，使用方法如下：
```python
import keras

TensorBoardcallback=keras.callbacks.TensorBoard(log_dir='./logs', 
histogram_freq=0, write_graph=True, write_images=False, 
embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)

model.fit(callbacks = [TensorBoardcallback])
```
TensorFlow的使用方法差不多：
```python
import tensorflow as tf 
TensorBoardcallback=tf.keras.callbacks.TensorBoard(log_dir='./logs', 
histogram_freq=0, write_graph=True, write_images=False, 
embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)

model.fit(callbacks = [TensorBoardcallback])
```
下面是参数介绍：

`log_dir`: 用来保存被 TensorBoard 分析的日志文件的文件名。

`histogram_freq`: 对于模型中各个层计算激活值和模型权重直方图的频率（训练轮数中）。 如果设置成 0 ，直方图不会被计算。对于直方图可视化的验证数据（或分离数据）一定要明确的指出。

`write_graph`: 是否在 TensorBoard 中可视化图像。 如果 write_graph 被设置为 True，日志文件会变得非常大。

`write_grads`: 是否在 TensorBoard 中可视化梯度值直方图。 histogram_freq 必须要大于 0 。

`batch_size`: 用以直方图计算的传入神经元网络输入批的大小。

`write_images`: 是否在 TensorBoard 中将模型权重以图片可视化。

`embeddings_freq`: 被选中的嵌入层会被保存的频率（在训练轮中）。

`embeddings_layer_names`: 一个列表，会被监测层的名字。 如果是 None 或空列表，那么所有的嵌入层都会被监测。

`embeddings_metadata`: 一个字典，对应层的名字到保存有这个嵌入层元数据文件的名字。 查看 详情 关于元数据的数据格式。 以防同样的元数据被用于所用的嵌入层，字符串可以被传入。

`embeddings_data`: 要嵌入在 embeddings_layer_names 指定的层的数据。 Numpy 数组（如果模型有单个输入）或 Numpy 数组列表（如果模型有多个输入）。 Learn ore about embeddings。

`update_freq`: 'batch' 或 'epoch' 或 整数。当使用 'batch' 时，在每个 batch 之后将损失和评估值写入到 TensorBoard 中。同样的情况应用到 'epoch' 中。如果使用整数，例如 10000，这个回调会在每 10000 个样本之后将损失和评估值写入到 TensorBoard 中。注意，频繁地写入到 TensorBoard 会减缓你的训练。
{% raw %}
***          
{% endraw %}
我个人推荐的参数设置如下：
```python
TensorBoardcallback = keras.callbacks.TensorBoard(
    log_dir='./logs',
    histogram_freq=1, batch_size=32,
    write_graph=True, write_grads=False, write_images=True,
    embeddings_freq=0, embeddings_layer_names=None,
    embeddings_metadata=None, embeddings_data=None, update_freq=500
)
```
### 2.数据可视化
运行如下命令：
```sh
tensorboard --logdir=/full_path_to_your_logs
```
在浏览器中打开： http://127.0.0.1:6006/

然后可以看到训练的过程和模型的数据